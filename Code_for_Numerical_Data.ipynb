{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59413ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: takes single instance of multiple_nan in which distance is greater than thresholds, \n",
    "# Output: give the imputed instances\n",
    "\n",
    "def process(inst,mean_std,class_center):\n",
    "    \n",
    "    # we count number of nan in instance\n",
    "    dummy_df = inst.copy()\n",
    "    nan_count = dummy_df.isna().sum(axis =1)\n",
    "    \n",
    "    # we create number of instances as per the nan_count\n",
    "    dummy_df = pd.concat([dummy_df]*nan_count.values[0])\n",
    "    \n",
    "    # we get the columns in which nan is present \n",
    "    cols = dummy_df.columns[dummy_df.isna().any()]\n",
    "    \n",
    "    # we replace nan values with the mean_std values to a single cell in an instance\n",
    "    for i in range(len(cols)):\n",
    "        dummy_df.iloc[i,cols[i]] = mean_std.iloc[0,cols[i]]\n",
    "    \n",
    "    # we impute mean values to rest nan values\n",
    "    dummy_df.fillna(class_center,inplace = True)\n",
    "    \n",
    "    # we find the single instance with shortest distance from the class_center\n",
    "    dummy_distances = []\n",
    "    for i in range(len(cols)):\n",
    "        dummy_distances.append(math.dist(class_center, dummy_df.iloc[i]))\n",
    "    \n",
    "    min_index = dummy_distances.index(min(dummy_distances))\n",
    "    output = dummy_df.iloc[min_index]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57701dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: data and class name\n",
    "# Output: complete and incomplete dataset of that particular class\n",
    "\n",
    "def data_split(data,c):\n",
    "    c_data = data[data[data.shape[1]-1]==c].dropna()\n",
    "    id = data[data[data.shape[1]-1]==c].isnull().any(axis =1)\n",
    "    ic_data = data[data[data.shape[1]-1] == c][id]\n",
    "    \n",
    "    return c_data,ic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrms_values = []\n",
    "fetched_original_data = pd.read_excel(r'give here original data location',header = None)\n",
    "fetched_data = pd.read_excel('give here location of data that has missing values',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f882a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = np.unique(data[data.shape[1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_imputed_data = data.copy()\n",
    "final_imputed_data = final_imputed_data.iloc[0:0]\n",
    "\n",
    "for i in class_list:\n",
    "    \n",
    "    #-----------------------------first algoritms---------------------------------------------------------------------#\n",
    "    \n",
    "    # splitting the data into complete and incomplete data based on class\n",
    "    globals()[\"complete_data_\"+str(i)],globals()[\"incomplete_data_\"+str(i)] = data_split(data,i)\n",
    "    \n",
    "    #----------------------------sending the complete data to the final imputed data----------------------------------#\n",
    "    final_imputed_data = final_imputed_data.append(globals()[\"complete_data_\"+str(i)])\n",
    "    \n",
    "    # class center and sandard deviation\n",
    "    class_center = globals()[\"complete_data_\"+str(i)].mean()\n",
    "    std_deviation = globals()[\"complete_data_\"+str(i)].std()\n",
    "    \n",
    "    # threshold calculation\n",
    "    distances = []\n",
    "    for j in  globals()[\"complete_data_\"+str(i)].index:\n",
    "        distances.append(math.dist(class_center,  globals()[\"complete_data_\"+str(i)].loc[j])) \n",
    "        \n",
    "    threshold = statistics.median(distances)\n",
    "    \n",
    "    #-----------------------------second algoritms-------------------------------------------------------------------#\n",
    "    \n",
    "    # addition of std and mean for the step2 of second algorithm\n",
    "    mean_list=globals()[\"complete_data_\"+str(i)].mean().tolist()\n",
    "    std_list=globals()[\"complete_data_\"+str(i)].std().tolist()\n",
    "    final_list=[mean_list, std_list]\n",
    "    mean_std=[sum(x) for x in zip(*final_list)]\n",
    "    mean_std = pd.DataFrame(np.array(mean_std).reshape(-1,len(mean_std)),columns = globals()[\"complete_data_\"+str(i)].columns)\n",
    "\n",
    "    # splitting the incomplete data into single_nan and multiple_nan\n",
    "    globals()['single_nan_'+str(i)] = globals()[\"incomplete_data_\"+str(i)][globals()[\"incomplete_data_\"+str(i)].isna().sum(axis =1) ==1]\n",
    "    globals()['multiple_nan_'+str(i)] = globals()[\"incomplete_data_\"+str(i)][globals()[\"incomplete_data_\"+str(i)].isna().sum(axis =1) >1]\n",
    "    \n",
    "    # imputing the class center values to the single_nan and multiple_nan\n",
    "    globals()['single_nan_imp_'+str(i)]=globals()['single_nan_'+str(i)].fillna(class_center)\n",
    "    globals()['multiple_nan_imp_'+str(i)]=globals()['multiple_nan_'+str(i)].fillna(class_center)\n",
    "    \n",
    "    # comparing the distance with the threshold, if distance greater we use the above mentioned function for the imputation\n",
    "    # Also a new variable multiple_nan_imp_ created for the new instances\n",
    "    for j in globals()['multiple_nan_imp_'+str(i)].index:\n",
    "        new_distance = math.dist(class_center, globals()['multiple_nan_imp_'+str(i)].loc[j])\n",
    "        if new_distance > threshold:\n",
    "            globals()['multiple_nan_imp_'+str(i)].loc[j] = process(globals()['multiple_nan_'+str(i)].loc[[j]],mean_std,class_center)\n",
    "\n",
    "    # comparing the distance with the threshold, if distance greater we use the above mentioned function for the imputation\n",
    "    # Also a new variable single_nan_imp_ created for the new instances\n",
    "    for j in globals()['single_nan_imp_'+str(i)].index:\n",
    "        new_distance = math.dist(class_center, globals()['single_nan_imp_'+str(i)].loc[j])\n",
    "        if new_distance > threshold:\n",
    "            globals()['single_nan_imp_'+str(i)].loc[j] = process(globals()['single_nan_'+str(i)].loc[[j]],mean_std,class_center)\n",
    "    \n",
    "    #---------------sending the single and multiple nan imputed values data to the final imputed data---------------#\n",
    "    final_imputed_data = final_imputed_data.append(globals()['single_nan_imp_'+str(i)])\n",
    "    final_imputed_data = final_imputed_data.append(globals()['multiple_nan_imp_'+str(i)])\n",
    "    \n",
    "# NRMS calculation\n",
    "nrms_numerator = np.linalg.norm(final_imputed_data - original_data)\n",
    "nrms_denomerator = np.linalg.norm(original_data)\n",
    "nrms = nrms_numerator/nrms_denomerator\n",
    "nrms_values.append(nrms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00678667756285096]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrms_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78784997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e3a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b07e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b734a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
